---
layout: default
---

<div class="row">
<p>
This page contains a non-exhaustive list of papers related to decision awareness in RL. We welcome additional resource suggestions via <a href="https://github.com/darl-workshop/darl-workshop.github.io/edit/master/resources.html">a pull request on GitHub</a>.
</p>
</div>


<div id="references" class="row"> 
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<h2>References (Alphabetical Order)</h2>
  
  <p>
  <div data-csl-entry-id="abachi2020policy" class="row">Abachi, R., Ghavamzadeh, M., &#38; Farahmand, A. (2020). Policy-aware model learning for policy gradient methods. <i>ArXiv Preprint ArXiv:2003.00030</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="amos2018differentiable" class="row">Amos, B., Rodriguez, I. D. J., Sacks, J., Boots, B., &#38; Kolter, J. Z. (2018). Differentiable mpc for end-to-end planning and control. <i>ArXiv Preprint ArXiv:1810.13400</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="ayoub2020model" class="row">Ayoub, A., Jia, Z., Szepesvari, C., Wang, M., &#38; Yang, L. (2020). Model-based reinforcement learning with value-targeted regression. <i>International Conference on Machine Learning</i>, 463–474.</div>
  </p>
  <p>
  <div data-csl-entry-id="balduzzi2015compatible" class="row">Balduzzi, D., &#38; Ghifary, M. (2015). Compatible value gradients for reinforcement learning of continuous deep policies. <i>ArXiv Preprint ArXiv:1509.03005</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="dabney2021" class="row">Dabney, W., Barreto, A., Rowland, M., Dadashi, R., Quan, J., Bellemare, M. G., &#38; Silver, D. (2021). The Value-Improvement Path: Towards Better Representations for Reinforcement Learning. <i>Proceedings of the AAAI Conference on Artificial Intelligence</i>, <i>35</i>(8), 7160-7168.</div>
  </p>
  <p>
  <div data-csl-entry-id="donti2017" class="row">Donti, P., Amos, B., &#38; Kolter, J. Z. (2017). Task-based End-to-end Model Learning in Stochastic Optimization. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, &#38; R. Garnett (Eds.), <i>Advances in Neural Information Processing Systems</i> (Vol. 30).</div>
  </p>
  <p>
  <div data-csl-entry-id="d2020learn" class="row">D’Oro, P., &#38; Jaskowski, W. (2020). How to Learn a Useful Critic? Model-based Action-Gradient-Estimator Policy Optimization. <i>Advances in Neural Information Processing Systems 33</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="d2020gradient" class="row">D’Oro, P., Metelli, A. M., Tirinzoni, A., Papini, M., &#38; Restelli, M. (2020). Gradient-aware model-based policy search. <i>Proceedings of the AAAI Conference on Artificial Intelligence</i>, <i>34</i>(4), 3801–3808.</div>
  </p>
  <p>
  <div data-csl-entry-id="East20" class="row">East, S., Gallieri, M., Masci, J., Koutnı́k, J., &#38; Cannon, M. (2020). Infinite-Horizon Differentiable Model Predictive Control. <i>8th International Conference on Learning Representations, ICLR 2020</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="farahmand2018iterative" class="row">Farahmand, A. (2018). Iterative Value-Aware Model Learning. <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 9072–9083.</div>
  </p>
  <p>
  <div data-csl-entry-id="farahmand2017value" class="row">Farahmand, A., Barreto, A. M. S., &#38; Nikovski, D. N. (2017). Value-Aware Loss Function for Model-based Reinforcement Learning. <i>Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (AISTATS)</i>, 1486–1494.</div>
  </p>
  <p>
  <div data-csl-entry-id="Farquhar18" class="row">Farquhar, G., Rocktäschel, T., Igl, M., &#38; Whiteson, S. (2018). TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning. <i>6th International Conference on Learning Representations, ICLR 2018</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="grimm2020value" class="row">Grimm, C., Barreto, A. M. S., Singh, S., &#38; Silver, D. (2020). The Value Equivalence Principle for Model-Based Reinforcement Learning. <i>Advances in Neural Information Processing Systems (NeurIPS)</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="kirsch2019improving" class="row">Kirsch, L., van Steenkiste, S., &#38; Schmidhuber, J. (2019). Improving generalization in meta reinforcement learning using learned objectives. <i>ArXiv Preprint ArXiv:1910.04098</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="lambert2020objective" class="row">Lambert, N., Amos, B., Yadan, O., &#38; Calandra, R. (2020). Objective Mismatch in Model-based Reinforcement Learning. <i>ArXiv Preprint ArXiv:2002.04523</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="mnih2015human" class="row">Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., Graves, A., Riedmiller, M., Fidjeland, A. K., Ostrovski, G., &#38; others. (2015). Human-level control through deep reinforcement learning. <i>Nature</i>, <i>518</i>(7540), 529–533.</div>
  </p>
  <p>
  <div data-csl-entry-id="nair2020goal" class="row">Nair, S., Savarese, S., &#38; Finn, C. (2020). Goal-aware prediction: Learning to model what matters. <i>International Conference on Machine Learning</i>, 7207–7219.</div>
  </p>
  <p>
  <div data-csl-entry-id="nikishin2021control" class="row">Nikishin, E., Abachi, R., Agarwal, R., &#38; Bacon, P.-L. (2021). Control-Oriented Model-Based Reinforcement Learning with Implicit Differentiation. <i>ArXiv Preprint ArXiv:2106.03273</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="oh2020discovering" class="row">Oh, J., Hessel, M., Czarnecki, W. M., Xu, Z., van Hasselt, H., Singh, S., &#38; Silver, D. (2020). Discovering reinforcement learning algorithms. <i>ArXiv Preprint ArXiv:2007.08794</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="oh2017value" class="row">Oh, J., Singh, S., &#38; Lee, H. (2017). Value prediction network. <i>Advances in Neural Information Processing Systems</i>, <i>30</i>.</div>
  </p>  
  <p>
  <div data-csl-entry-id="rajeswaran2020game" class="row">Rajeswaran, A., Mordatch, I., &#38; Kumar, V. (2020). A game theoretic framework for model based reinforcement learning. <i>International Conference on Machine Learning</i>, 7953–7963.</div>
  </p>
  <p>
  <div data-csl-entry-id="schrittwieser2020mastering" class="row">Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L., Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., &#38; others. (2020). Mastering atari, go, chess and shogi by planning with a learned model. <i>Nature</i>, <i>588</i>(7839), 604–609.</div>
  </p>
  <p>
  <div data-csl-entry-id="silver2017predictron" class="row">Silver, D., Hasselt, H., Hessel, M., Schaul, T., Guez, A., Harley, T., Dulac-Arnold, G., Reichert, D., Rabinowitz, N., Barreto, A., &#38; others. (2017). The predictron: End-to-end learning and planning. <i>International Conference on Machine Learning</i>, 3191–3199.</div>
  </p>
  <p>
  <div data-csl-entry-id="silver2021reward" class="row">Silver, D., Singh, S., Precup, D., &#38; Sutton, R. S. (2021). Reward is enough. <i>Artificial Intelligence</i>, <i>299</i>, 103535.</div>
  </p>
  <p>
  <div data-csl-entry-id="tamar2016value" class="row">Tamar, A., Wu, Y., Thomas, G., Levine, S., &#38; Abbeel, P. (2016). Value iteration networks. <i>Advances in Neural Information Processing Systems</i>, <i>29</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="voelcker2021value" class="row">Voelcker, C. A., Liao, V., Garg, A., &#38; Farahmand, A. (2021). Value Gradient weighted Model-Based Reinforcement Learning. <i>International Conference on Learning Representations</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="xu2018algorithmic" class="row">Xu, H., Li, Y., Tian, Y., Darrell, T., &#38; Ma, T. (2018). Algorithmic framework for model-based reinforcement learning with theoretical guarantees. <i>ArXiv Preprint ArXiv:1807.03858</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="xu2020meta" class="row">Xu, Z., van Hasselt, H., Hessel, M., Oh, J., Singh, S., &#38; Silver, D. (2020). Meta-gradient reinforcement learning with an objective discovered online. <i>ArXiv Preprint ArXiv:2007.08433</i>.</div>
  </p>
  <p>
  <div data-csl-entry-id="xu2018meta" class="row">Xu, Z., van Hasselt, H., &#38; Silver, D. (2018). Meta-gradient reinforcement learning. <i>ArXiv Preprint ArXiv:1805.09801</i>.</div>
  </p>
</div>
